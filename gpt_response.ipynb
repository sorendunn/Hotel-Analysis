{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "import json \n",
    "import pandas as pd\n",
    "import time\n",
    "import tiktoken\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-fS0CBDJMYoVnmduDfEA8jBHe\"\n",
    "openai.api_key = \"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\"\n",
    "#openai.Model.list()\n",
    "\n",
    "## This funciton handles prompt imput and ChatGPT output\n",
    "def gpt_response(prompt):\n",
    "\n",
    "    \n",
    "    time.sleep(2.0)\n",
    "\n",
    "\n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': 'Bearer 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',\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': 'gpt-3.5-turbo',\n",
    "        'messages': [{'role': 'user', 'content': 'Summarize the following reviews: %s' % prompt}],\n",
    "        'temperature': 0.7,\n",
    "    }\n",
    "\n",
    "\n",
    "    response = requests.post(url, headers = headers, data = json.dumps(data))\n",
    "    return (json.loads(response.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get data from the json file into dataframe\n",
    "data = pd.read_json('restrauntData.json')\n",
    "\n",
    "##Extracts review text form data\n",
    "def get_text(x):\n",
    "    review_list = []\n",
    "    for i in x:\n",
    "        review_list.append(i[\"text\"])\n",
    "    return review_list\n",
    "\n",
    "data[\"review_list\"] = data[\"reviews\"].apply(get_text)\n",
    "data[\"latitude\"] = data[\"location\"].apply(lambda x: x[\"lat\"])\n",
    "data[\"longitude\"] = data[\"location\"].apply(lambda x: x[\"lng\"])\n",
    "data = data[data[\"latitude\"] > 41.85]\n",
    "# data.to_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##helps join all text, filters out None entries\n",
    "def join_text(dfx):\n",
    "    return_str = ''\n",
    "    return_str = return_str.join(filter(None,dfx))\n",
    "    return return_str\n",
    "\n",
    "string_reviews = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "def summarize_reviews(rev_list):\n",
    "    # Combine all reviews into a single string\n",
    "    all_reviews = \"\".join(rev_list)\n",
    "\n",
    "    # Tokenize the string into sentences and words\n",
    "    sentences = sent_tokenize(all_reviews)\n",
    "    words = word_tokenize(all_reviews)\n",
    "\n",
    "    # Create a frequency distribution of words\n",
    "    freq_dist = FreqDist(words)\n",
    "\n",
    "    # Create a list of the most common words\n",
    "    common_words = [word for word, freq in freq_dist.most_common(100)]\n",
    "\n",
    "    # Create a summary by selecting the most relevant sentences\n",
    "    summary_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence_words = word_tokenize(sentence)\n",
    "        relevance = sum(1 for word in sentence_words if word in common_words)\n",
    "        if relevance > 0:\n",
    "            summary_sentences.append((sentence, relevance))\n",
    "\n",
    "    # Sort the summary sentences by relevance\n",
    "    summary_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the first n sentences as the summary\n",
    "    summary = [sentence for sentence, relevance in summary_sentences[:2]]\n",
    "    return \"\".join(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a new df with first colum as stirng reviews\n",
    "string_reviews[\"str_rev\"] =  data[\"reviews\"].copy()\n",
    "\n",
    "##Create new colum with reviews concaenated in the same string.\n",
    "string_reviews[\"str_rev\"] =  data[\"review_list\"].apply(join_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make  batches for data\n",
    "def make_batches(list):\n",
    "    for chunk in np.array_split(list, 2):\n",
    "        chunk_str = chunk.apply(join_text)\n",
    "    return chunk_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Out of everything?  How...',\n",
       " 'Rude employees, they rang the order up in pieces instead of as a meal then hurried me away by wavijg their hand at me to move. Old cold food and the lemonade extremely watery.',\n",
       " \"Ordered un-salted bites and was told they'd make them and it would take 10 mins. I waited and then recieved salted... then some guy said, oh we don't make those and I explained I just waited for those as I was told they were being made. I told him I don't eat huge chunks of salt. He thru them out and gave 2 reg ones. Annoyed!!!!! The one I placed the order with was super sweet. The skinny little guy beside him....has a bad attitude issue and definitely shouldn't be working with the public\",\n",
       " None,\n",
       " 'pretzel had just come out of the oven, dipped in butter + cinnamon sugar! service was fine, no wait in line. very happy with this treat!',\n",
       " None,\n",
       " 'Wasnâ€™t going to open for 30 minutes reported the staff but pretzels already being set out waiting to get cold.  Maybe made the previous night.',\n",
       " \"Didn't expect much being in an airport but the pretzel bites weren't even a little warm.  Waste of $10.\",\n",
       " 'The lady at the register was very sweet and patient. The pretzel was soft but not warmed enough. Good for an airport ðŸ¥¨',\n",
       " \"The girl working there was dumping a tray of the smaller pretzels into the tub and a good amount fell behind the tub and she picked them up and put them in. That's very unsanitary and makes you wonder where else they're unsanitary\",\n",
       " 'Would have been great! Currently closed for the pandemic.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review_list\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Out of everything?  How..., Rude employees, t...\n",
       "1      [Not open during it's peak hours, doesn't foll...\n",
       "2      [Very nice bloody Maryâ€™s and good service from...\n",
       "3      [None, Very bland. Over cooked. High priced an...\n",
       "4      [The staff, the ambience, the drinks, and the ...\n",
       "                             ...                        \n",
       "295    [Just don't do it. There are plenty of restaur...\n",
       "296    [Unbelievably delicious chicken!!! Very fair p...\n",
       "297    [None, Loved this spot ! Food was so fresh . H...\n",
       "298    [Kelly is fantastic.Gyro was good,a little.dry...\n",
       "299    [None, None, None, Amazing place to have afric...\n",
       "Name: review_list, Length: 225, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review_list\"] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

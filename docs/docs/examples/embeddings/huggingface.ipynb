{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNxy-Erkw8si"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJX8-Hu-w8sk"
      },
      "source": [
        "# Local Embeddings with HuggingFace\n",
        "\n",
        "LlamaIndex has support for HuggingFace embedding models, including BGE, Instructor, and more.\n",
        "\n",
        "Furthermore, we provide utilities to create and use ONNX models using the [Optimum library](https://huggingface.co/docs/transformers/serialization#exporting-a-transformers-model-to-onnx-with-optimumonnxruntime) from HuggingFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHvCod5Vw8sk"
      },
      "source": [
        "## HuggingFaceEmbedding\n",
        "\n",
        "The base `HuggingFaceEmbedding` class is a generic wrapper around any HuggingFace model for embeddings. All [embedding models](https://huggingface.co/models?library=sentence-transformers) on Hugging Face should work. You can refer to the [embeddings leaderboard](https://huggingface.co/spaces/mteb/leaderboard) for more recommendations.\n",
        "\n",
        "This class depends on the sentence-transformers package, which you can install with `pip install sentence-transformers`.\n",
        "\n",
        "NOTE: if you were previously using a `HuggingFaceEmbeddings` from LangChain, this should give equivalent results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUpq6UkIw8sk"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SlLS7HH2w8sl",
        "outputId": "bcfd1073-db89-49a9-fe79-138fd779b37a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-embeddings-huggingface\n",
            "  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.7)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-embeddings-huggingface)\n",
            "  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.10)\n",
            "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
            "  Downloading minijinja-2.5.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.36)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.4.2)\n",
            "Collecting nltk>3.8.1 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
            "Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
            "Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading minijinja-2.5.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (915 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m915.6/915.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, dirtyjson, tenacity, nltk, mypy-extensions, minijinja, marshmallow, typing-inspect, tiktoken, dataclasses-json, llama-index-core, llama-index-embeddings-huggingface\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 dirtyjson-1.0.8 filetype-1.2.0 llama-index-core-0.11.23 llama-index-embeddings-huggingface-0.3.1 marshmallow-3.23.1 minijinja-2.5.0 mypy-extensions-1.0.0 nltk-3.9.1 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-embeddings-instructor\n",
            "  Downloading llama_index_embeddings_instructor-0.2.1-py3-none-any.whl.metadata (759 bytes)\n",
            "Collecting instructorembedding<2.0.0,>=1.0.1 (from llama-index-embeddings-instructor)\n",
            "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-instructor) (0.11.23)\n",
            "Collecting sentence-transformers<3.0.0,>=2.2.2 (from llama-index-embeddings-instructor)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-instructor) (2.5.0+cu121)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.16.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (4.44.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.0.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (24.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.9.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.1.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.19.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.23.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (3.5.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.2)\n",
            "Downloading llama_index_embeddings_instructor-0.2.1-py3-none-any.whl (3.6 kB)\n",
            "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: instructorembedding, sentence-transformers, llama-index-embeddings-instructor\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.2.1\n",
            "    Uninstalling sentence-transformers-3.2.1:\n",
            "      Successfully uninstalled sentence-transformers-3.2.1\n",
            "Successfully installed instructorembedding-1.0.1 llama-index-embeddings-instructor-0.2.1 sentence-transformers-2.7.0\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-embeddings-huggingface\n",
        "%pip install llama-index-embeddings-instructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a5Xi9V8xw8sm",
        "outputId": "3b4171cc-edb6-49aa-baf6-ee1cddde6b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.11.23-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.23 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.11.23)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.52.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (3.10.10)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2024.10.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.27.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.4-py3-none-any.whl.metadata (814 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (4.12.3)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
            "  Downloading llama_parse-0.5.13-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.4.0,>=0.3.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.23->llama-index) (3.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.23->llama-index) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.23->llama-index) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.23->llama-index) (0.2.0)\n",
            "Downloading llama_index-0.11.23-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.3.0-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.8/176.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.13-py3-none-any.whl (13 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-cloud, llama-index-legacy, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed llama-cloud-0.1.4 llama-index-0.11.23 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.3.0 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.13 pypdf-5.1.0 striprtf-0.0.26\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/agentless_s\n",
        "!mkdir testbed"
      ],
      "metadata": {
        "id": "mhbHKKBdxkxU",
        "outputId": "f8d729ca-5e33-467d-dabb-f0c822c7cfe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/agentless_s'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/django/django.git testbed/django\n",
        "!git clone https://github.com/sympy/sympy.git testbed/sympy\n",
        "!git clone https://github.com/matplotlib/matplotlib.git testbed/matplotlib\n",
        "!git clone https://github.com/scikit-learn/scikit-learn.git testbed/scikit-learn\n",
        "!git clone https://github.com/pytest-dev/pytest.git testbed/pytest\n",
        "!git clone https://github.com/sphinx-doc/sphinx.git testbed/sphinx\n",
        "!git clone https://github.com/psf/requests.git testbed/requests\n",
        "!git clone https://github.com/pylint-dev/pylint.git testbed/pylint\n",
        "!git clone https://github.com/astropy/astropy.git testbed/astropy\n",
        "!git clone https://github.com/pydata/xarray.git testbed/xarray\n",
        "!git clone https://github.com/mwaskom/seaborn.git testbed/seaborn\n",
        "!git clone https://github.com/pallets/flask.git testbed/flask"
      ],
      "metadata": {
        "id": "Bc6CAIjI_OKg",
        "outputId": "8672569b-d831-42e3-ac6f-dd0fdc32b6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'testbed/django'...\n",
            "remote: Enumerating objects: 534173, done.\u001b[K\n",
            "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
            "remote: Compressing objects: 100% (283/283), done.\u001b[K\n",
            "remote: Total 534173 (delta 291), reused 290 (delta 190), pack-reused 533699 (from 1)\u001b[K\n",
            "Receiving objects: 100% (534173/534173), 258.23 MiB | 16.94 MiB/s, done.\n",
            "Resolving deltas: 100% (383307/383307), done.\n",
            "Cloning into 'testbed/sympy'...\n",
            "remote: Enumerating objects: 409951, done.\u001b[K\n",
            "remote: Counting objects: 100% (1950/1950), done.\u001b[K\n",
            "remote: Compressing objects: 100% (940/940), done.\u001b[K\n",
            "remote: Total 409951 (delta 1268), reused 1536 (delta 1004), pack-reused 408001 (from 1)\u001b[K\n",
            "Receiving objects: 100% (409951/409951), 183.36 MiB | 15.96 MiB/s, done.\n",
            "Resolving deltas: 100% (326822/326822), done.\n",
            "Cloning into 'testbed/matplotlib'...\n",
            "remote: Enumerating objects: 332455, done.\u001b[K\n",
            "remote: Counting objects: 100% (1937/1937), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1423/1423), done.\u001b[K\n",
            "remote: Total 332455 (delta 1083), reused 1143 (delta 511), pack-reused 330518 (from 1)\u001b[K\n",
            "Receiving objects: 100% (332455/332455), 446.59 MiB | 16.52 MiB/s, done.\n",
            "Resolving deltas: 100% (230568/230568), done.\n",
            "Cloning into 'testbed/scikit-learn'...\n",
            "remote: Enumerating objects: 253160, done.\u001b[K\n",
            "remote: Counting objects: 100% (712/712), done.\u001b[K\n",
            "remote: Compressing objects: 100% (550/550), done.\u001b[K\n",
            "remote: Total 253160 (delta 389), reused 342 (delta 162), pack-reused 252448 (from 1)\u001b[K\n",
            "Receiving objects: 100% (253160/253160), 161.06 MiB | 16.31 MiB/s, done.\n",
            "Resolving deltas: 100% (196615/196615), done.\n",
            "Cloning into 'testbed/pytest'...\n",
            "remote: Enumerating objects: 107548, done.\u001b[K\n",
            "remote: Counting objects: 100% (655/655), done.\u001b[K\n",
            "remote: Compressing objects: 100% (383/383), done.\u001b[K\n",
            "remote: Total 107548 (delta 376), reused 455 (delta 240), pack-reused 106893 (from 1)\u001b[K\n",
            "Receiving objects: 100% (107548/107548), 34.06 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (75639/75639), done.\n",
            "Cloning into 'testbed/sphinx'...\n",
            "remote: Enumerating objects: 171032, done.\u001b[K\n",
            "remote: Counting objects: 100% (2551/2551), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1309/1309), done.\u001b[K\n",
            "remote: Total 171032 (delta 1475), reused 1998 (delta 1093), pack-reused 168481 (from 1)\u001b[K\n",
            "Receiving objects: 100% (171032/171032), 95.33 MiB | 16.12 MiB/s, done.\n",
            "Resolving deltas: 100% (125929/125929), done.\n",
            "Cloning into 'testbed/requests'...\n",
            "remote: Enumerating objects: 25993, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 25993 (delta 35), reused 40 (delta 21), pack-reused 25924 (from 1)\u001b[K\n",
            "Receiving objects: 100% (25993/25993), 12.73 MiB | 8.61 MiB/s, done.\n",
            "Resolving deltas: 100% (17060/17060), done.\n",
            "Cloning into 'testbed/pylint'...\n",
            "remote: Enumerating objects: 88175, done.\u001b[K\n",
            "remote: Counting objects: 100% (1244/1244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (800/800), done.\u001b[K\n",
            "remote: Total 88175 (delta 716), reused 831 (delta 428), pack-reused 86931 (from 1)\u001b[K\n",
            "Receiving objects: 100% (88175/88175), 41.00 MiB | 15.49 MiB/s, done.\n",
            "Resolving deltas: 100% (58822/58822), done.\n",
            "Cloning into 'testbed/astropy'...\n",
            "remote: Enumerating objects: 281615, done.\u001b[K\n",
            "remote: Counting objects: 100% (3082/3082), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1340/1340), done.\u001b[K\n",
            "remote: Total 281615 (delta 2130), reused 2481 (delta 1741), pack-reused 278533 (from 1)\u001b[K\n",
            "Receiving objects: 100% (281615/281615), 162.89 MiB | 16.33 MiB/s, done.\n",
            "Resolving deltas: 100% (217838/217838), done.\n",
            "Cloning into 'testbed/xarray'...\n",
            "remote: Enumerating objects: 45397, done.\u001b[K\n",
            "remote: Counting objects: 100% (1181/1181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (648/648), done.\u001b[K\n",
            "remote: Total 45397 (delta 835), reused 748 (delta 533), pack-reused 44216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45397/45397), 47.65 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (36172/36172), done.\n",
            "Cloning into 'testbed/seaborn'...\n",
            "remote: Enumerating objects: 19125, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 19125 (delta 2), reused 10 (delta 2), pack-reused 19112 (from 1)\u001b[K\n",
            "Receiving objects: 100% (19125/19125), 53.04 MiB | 12.39 MiB/s, done.\n",
            "Resolving deltas: 100% (14058/14058), done.\n",
            "Cloning into 'testbed/flask'...\n",
            "remote: Enumerating objects: 25242, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 25242 (delta 185), reused 242 (delta 132), pack-reused 24914 (from 1)\u001b[K\n",
            "Receiving objects: 100% (25242/25242), 10.42 MiB | 15.53 MiB/s, done.\n",
            "Resolving deltas: 100% (16881/16881), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility Functions\n",
        "import subprocess\n",
        "def checkout_commit(repo_path, commit_id):\n",
        "    \"\"\"Checkout the specified commit in the given local git repository.\n",
        "    First discards any untracked changes in the repository.\n",
        "    :param repo_path: Path to the local git repository\n",
        "    :param commit_id: Commit ID to checkout\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Clean untracked files and directories\n",
        "        print(f\"Cleaning untracked files in repository at {repo_path}...\")\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"clean\", \"-fd\"], check=True)\n",
        "\n",
        "        # Discard changes in tracked files\n",
        "        print(\"Discarding changes in tracked files...\")\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"reset\", \"--hard\"], check=True)\n",
        "\n",
        "        # Change directory to the provided repository path and checkout the specified commit\n",
        "        print(f\"Checking out commit {commit_id}...\")\n",
        "        subprocess.run([\"git\", \"-C\", repo_path, \"checkout\", commit_id], check=True)\n",
        "        print(\"Commit checked out successfully.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"An error occurred while running git command: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "def get_all_file_paths(folder_path, base_dir):\n",
        "    \"\"\"\n",
        "    Returns a list of absolute file paths for all files in the given folder and its subfolders.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder to search\n",
        "\n",
        "    Returns:\n",
        "        list: A list of absolute file paths\n",
        "    \"\"\"\n",
        "    file_paths = []\n",
        "\n",
        "    # Convert to absolute path if relative path is given\n",
        "    folder_path = os.path.abspath(folder_path)\n",
        "\n",
        "    # Check if the folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        raise ValueError(f\"The folder '{folder_path}' does not exist\")\n",
        "\n",
        "    # Walk through the directory tree\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        # Add the absolute path of each file to the list\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            repo_file_path = os.path.relpath(file_path, folder_path)\n",
        "            file_paths.append(repo_file_path)\n",
        "\n",
        "    return file_paths"
      ],
      "metadata": {
        "id": "B77L7e6z-Ez9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main retrieve function\n",
        "import os\n",
        "from llama_index.core import (\n",
        "    Document,\n",
        "    StorageContext,\n",
        "    VectorStoreIndex,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "def retrieve(\n",
        "    files,\n",
        "    prompt,\n",
        "    embedding_model,\n",
        "    save_dir,\n",
        "    top_k,\n",
        "    file_to_contents,\n",
        "):\n",
        "    # Check if index files exist in save_dir\n",
        "    if os.path.exists(save_dir) and os.path.isdir(save_dir) and os.listdir(save_dir):\n",
        "        storage_context = StorageContext.from_defaults(persist_dir=save_dir)\n",
        "        index = load_index_from_storage(storage_context)\n",
        "        print(\"Loading existing index from storage\")\n",
        "    else:\n",
        "        print(\"Creating new index\")\n",
        "        documents = []\n",
        "        for file in files:\n",
        "            file_content = file_to_contents[file]\n",
        "            meta_data = {\n",
        "                \"File Name\": file,\n",
        "            }\n",
        "            doc = Document(\n",
        "                text=file_content,\n",
        "                metadata=meta_data,\n",
        "                metadata_template=\"{key}: {value}\",\n",
        "                text_template=\"{metadata_str}\\n-----\\nCode:\\n{content}\",\n",
        "            )\n",
        "            documents.append(doc)\n",
        "\n",
        "        index = VectorStoreIndex.from_documents(documents, embed_model=embedding_model)\n",
        "        index.storage_context.persist(persist_dir=save_dir)\n",
        "\n",
        "    retriever = VectorIndexRetriever(index=index, similarity_top_k=top_k)\n",
        "    retrieved_documents = retriever.retrieve(prompt)\n",
        "\n",
        "    file_names = []\n",
        "    file_contents = []\n",
        "    for node in retrieved_documents:\n",
        "        file = node.metadata[\"File Name\"]\n",
        "        if file not in file_names:\n",
        "            file_names.append(file)\n",
        "            file_contents.append(file_to_contents[file])\n",
        "\n",
        "    return file_names, file_contents"
      ],
      "metadata": {
        "id": "4swpqlLD-Fhu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent\n",
        "import json\n",
        "import os\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from random import shuffle\n",
        "import sys\n",
        "import pandas as pd\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "repo_to_top_folder = {\n",
        "    \"django/django\": \"django\",\n",
        "    \"sphinx-doc/sphinx\": \"sphinx\",\n",
        "    \"scikit-learn/scikit-learn\": \"scikit-learn\",\n",
        "    \"sympy/sympy\": \"sympy\",\n",
        "    \"pytest-dev/pytest\": \"pytest\",\n",
        "    \"matplotlib/matplotlib\": \"matplotlib\",\n",
        "    \"astropy/astropy\": \"astropy\",\n",
        "    \"pydata/xarray\": \"xarray\",\n",
        "    \"mwaskom/seaborn\": \"seaborn\",\n",
        "    \"psf/requests\": \"requests\",\n",
        "    \"pylint-dev/pylint\": \"pylint\",\n",
        "    \"pallets/flask\": \"flask\",\n",
        "}\n",
        "\n",
        "# Create locks for each repo to prevent concurrent access\n",
        "repo_locks = {repo: threading.Lock() for repo in repo_to_top_folder.keys()}\n",
        "output_lock = threading.Lock()\n",
        "\n",
        "splits = {\n",
        "    \"dev\": \"data/dev-00000-of-00001.parquet\",\n",
        "    \"test\": \"data/test-00000-of-00001.parquet\",\n",
        "}\n",
        "swe_df = pd.read_parquet(\"hf://datasets/princeton-nlp/SWE-bench_Lite/\" + splits[\"test\"])\n",
        "\n",
        "RETRIEVAL_INSTRUCTION = (\n",
        "    \"\\n\\nFind code the code which need to be edited to solve the above issue\"\n",
        ")\n",
        "\n",
        "# RETRIEVAL_MODEL = OpenAIEmbedding(model_name=\"text-embedding-3-large\") # OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
        "# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "\n",
        "# SEE: https://huggingface.co/docs/hub/security-tokens\n",
        "# We just need a token with read permissions for this demo\n",
        "HF_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
        "RETRIEVAL_MODEL = HuggingFaceEmbedding(model_name=\"nvidia/NV-Embed-v2\")\n",
        "\n",
        "\n",
        "# RERANK_MODEL = OpenAIEmbedding(model_name=\"text-embedding-3-large\")\n",
        "\n",
        "\n",
        "def retrieve_instance(args, row, output_path):\n",
        "    \"\"\"Process a single row from the DataFrame\"\"\"\n",
        "    original_prompt = row[\"problem_statement\"]\n",
        "    persist_dir = os.path.join(\n",
        "        args.base_path, \"fl\", \"embeddings_cornstack\", row[\"instance_id\"]\n",
        "    )\n",
        "\n",
        "    file_dir = os.path.join(args.testbed_dir, repo_to_top_folder[row[\"repo\"]])\n",
        "    full_prompt = original_prompt + RETRIEVAL_INSTRUCTION\n",
        "\n",
        "    with repo_locks[row[\"repo\"]]:\n",
        "        checkout_commit(file_dir, row[\"base_commit\"])\n",
        "        files = get_all_file_paths(file_dir, args.testbed_dir)\n",
        "\n",
        "        # Filter files\n",
        "        files = [\n",
        "            file_path\n",
        "            for file_path in files\n",
        "            if file_path.endswith(\".py\") and (not \"/test\" in file_path)\n",
        "        ]\n",
        "        file_to_contents = {}\n",
        "        for file in files:\n",
        "            with open(os.path.join(file_dir, file), \"r\") as f:\n",
        "                file_to_contents[file] = f.read()\n",
        "\n",
        "\n",
        "    file_names, file_contents = retrieve(\n",
        "        files,\n",
        "        full_prompt,\n",
        "        RETRIEVAL_MODEL,\n",
        "        persist_dir,\n",
        "        args.retrieve_num,\n",
        "        file_to_contents\n",
        "    )\n",
        "\n",
        "        # For back-compatibility\n",
        "        # file_names = [os.path.join(repo_to_top_folder[row[\"repo\"]], file) for file in file_names]\n",
        "\n",
        "    result = {\n",
        "        \"instance_id\": row[\"instance_id\"],\n",
        "        \"problem_description\": original_prompt,\n",
        "        \"found_files\": file_names,\n",
        "        \"file_contents\": file_contents,\n",
        "    }\n",
        "\n",
        "    # Write the result to the output file with a lock to prevent concurrent writing\n",
        "    with output_lock:\n",
        "        with open(output_path, \"a\") as f:\n",
        "            json_line = json.dumps(result)\n",
        "            f.write(json_line + \"\\n\")\n",
        "            f.flush()  # Ensure the line is written immediately\n",
        "\n",
        "    return result\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.base_path = \"/content/\"\n",
        "        self.testbed_dir = \"/content/testbed\"\n",
        "        self.retrieve_num = 50\n",
        "        self.output_file = \"retrieved_mbet.jsonl\"\n",
        "        self.max_workers = 1\n",
        "        self.embedding_dir = \"mbet_embeddings\"\n",
        "\n",
        "args = Args()\n",
        "\n",
        "output_path = os.path.join(args.base_path, args.output_file)\n",
        "with open(output_path, \"w\") as f:\n",
        "    pass  # Just create/clear the file\n",
        "\n",
        "if args.max_workers == 1:\n",
        "    for _, row in swe_df.iterrows():\n",
        "        retrieve_instance(args, row, output_path)\n",
        "else:\n",
        "    with ThreadPoolExecutor(max_workers=args.max_workers) as executor:\n",
        "        rows_list = list(swe_df.iterrows())[:5]\n",
        "        shuffle(rows_list)\n",
        "\n",
        "        future_to_row = {\n",
        "            executor.submit(retrieve_instance, args, row, output_path): row\n",
        "            for _, row in rows_list\n",
        "        }\n",
        "\n",
        "        for future in concurrent.futures.as_completed(future_to_row):\n",
        "            row = future_to_row\n"
      ],
      "metadata": {
        "id": "Hi3XxAfHyuD7",
        "outputId": "1fc6d26e-391f-4c32-9ecd-65f9df18af95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Checking out commit 04b15022e8d1f49af69d8a1e6cd678f31f1280ff...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 514efa3129792ec2abb2444f3e7aeb3f21a38386...\n",
            "Cleaning untracked files in repository at /content/testbed/astropy...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Checking out commit a5917978be39d13cd90b517e1de4e7a539ffaa48...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Checking out commit b17abcb09cbcee80a90f6750e0f9b53f0247656c...\n",
            "Checking out commit 50c3ac6fa9b7c8a94a6d1dc87edf775e3bc4d575...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/requests...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit a0df2cbb10419037d11d04352b3175405ab52941...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Checking out commit 08a4ee06510ae45562c228eefbdcaac84bd38c7a...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Checking out commit f6a781f77f5ddf1204c60ca7c544809407d4a807...\n",
            "Commit checked out successfully.Commit checked out successfully.\n",
            "\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 62000f37b8821573ba00280524ffb4ac4a380875...\n",
            "Checking out commit 78ad4b4b0201003792bfdbf1a7781cbc9ee03539...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'clean', '-fd']' returned non-zero exit status 128.\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit b9af885473ad7e34b5b0826cb424dd26d8934670...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sphinx...\n",
            "Discarding changes in tracked files...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Checking out commit 195e911f1dab04b8ddeacbe04b7d214aaf81bb0b...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Checking out commit 93e892bb645b16ebaf287beb5fe7f3ffe8d10408...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/astropy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Checking out commit d16bfe05a744909de4b27f5875fe0d4ed41ce607...\n",
            "Checking out commit 879cc3da6249e920b8d54518a0ae06de835d7373...\n",
            "Checking out commit d3fcdb72bfcbb560eb45264ac1c03f359436edef...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 580e644f24f1c5ae5b94784fb73a9953a178fd26...\n",
            "Commit checked out successfully.\n",
            "Creating new indexCleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit ef082ebb84f00e38af4e8880d04e8365c2766d34...\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 4fd3044ca0135da903a70dfb66992293f529ecf1...\n",
            "Checking out commit 514579c655bf22e2af14f0743376ae1d7befe345...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/astropy...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Checking out commit d5bd3f68bb6d5ce3a61bdce9883ee750d1afade5...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' returned non-zero exit status 128.\n",
            "Commit checked out successfully.\n",
            "Checking out commit df46b329e0900e9e4dc1d60816c1dce6dfc1094e...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit f91de695585c1fbc7d4f49ee061f64fcb1c2c4d8...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/flask...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 182ce3dd15dfa3537391c3efaf9c3ff407d134d4...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit b7c5ba2bf3ffd5cf453b25af7c8ddd9a639800cb...\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new indexCreating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Cleaning untracked files in repository at /content/testbed/scikit-learn...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 2c83657ff1c62fc2761b639469fdac7f7561a72a...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 1c8668b0a021832386470ddf740d834e02c66f69...\n",
            "Checking out commit 08a4ee06510ae45562c228eefbdcaac84bd38c7a...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 66f7956984cbfc3647e867c6e5fde889a89c64ef...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/xarray...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit e56905889c836c736152b11a7e6117a229715975...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit e727339af6dc22321b00f52d971cda39e4ce89fb...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sphinx...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7ca279e33aebb60168d35e6be4ed059f4a68f2c1...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Commit checked out successfully.\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 9ef28fba5b4d6d0168237c9c005a550e6dc27d81...\n",
            "Creating new index\n",
            "Checking out commit 979f61abd322507aafced9627702362e541ec34e...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/pytest...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7f7a36478abe7dd1fa993b115d22606aa0e35e88...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 97fc1154992f64cfb2f86321155a7404efeb2d8a...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Creating new index\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Checking out commit e8c22f6eac7314be8d92590bfff92ced79ee03e2...\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 4a72da71001f154ea60906a2f74898d32b7322a7...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit a4881f5e5d7ee38b7e83301331a0b4962845ef8a...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c5cd8783825b5f6384417dac5f3889b4210b7d08...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit d5276398046ce4a102776a1e67dcac2884d80dfe...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pylint...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 397c1703e8ae6349d33f7b99f45b2ccaf581e666...\n",
            "Checking out commit 447980e72ac01da1594dd3373a03ba40b7ee6f80...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 60dc957a825232fdda9138e2f8878b2ca407a7c9...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 03cadb912c78b769d6bf4a943a2a35fc1d952960...\n",
            "Commit checked out successfully.\n",
            "Creating new indexCleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7f9e4524d6b23424cf44fbe1bf1f4e70f6bb066e...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 580e644f24f1c5ae5b94784fb73a9953a178fd26...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 514efa3129792ec2abb2444f3e7aeb3f21a38386...\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/scikit-learn...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit cd25abee0ad0ac95225d4a9be8948eff69f49690...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 979f61abd322507aafced9627702362e541ec34e...\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 3dff1b98a78f28c953ae2140b69356b8391e399c...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 58e78209c8577b9890e957b624466e5beed7eb08...\n",
            "Checking out commit d559cb02da30f74debbb1fc3a46de0df134d2d80...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit d60497958f6dea7f5e25bc41e9107a6a63694d01...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pytest...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7f7a36478abe7dd1fa993b115d22606aa0e35e88...\n",
            "Commit checked out successfully.\n",
            "Checking out commit f9e030b57623bebdc2efa7f297c1b5ede08fcebf...\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pytest...\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 56bf819c2f4eaf8b36bd8c42c06bb59d5a3bfc0f...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Checking out commit 1d3327b8e90a186df6972991963a5ae87053259d...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 93e892bb645b16ebaf287beb5fe7f3ffe8d10408...\n",
            "Checking out commit 97fc1154992f64cfb2f86321155a7404efeb2d8a...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit b9af885473ad7e34b5b0826cb424dd26d8934670...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit d3fcdb72bfcbb560eb45264ac1c03f359436edef...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Creating new index\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c61219a7ae051d2baab53f041e00592011fc550c...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 2c83657ff1c62fc2761b639469fdac7f7561a72a...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c5cef2499d6eed024b0db5c792d6ec7c53baa470...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit af39f1edffcd828f05cfdd04f2e59506bb4a27bc...\n",
            "Checking out commit 19fc6376ce67d01ca37a91ef2f55ef769f50513a...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit d26b2424437dabeeca94d7900b37d2df4410da0c...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 36fa071d6ebd18a61c4d7f1b5c9d17106134bd44...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c5e373d48cbdd923575956fed477b63d66d9603f...\n",
            "Checking out commit fb536869fb7aa28b2695ad7a3b70949926b291c4...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 6a970a8b4600eb91be25f38caed0a52269d6303d...\n",
            "Cleaning untracked files in repository at /content/testbed/astropy...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Checking out commit d5bd3f68bb6d5ce3a61bdce9883ee750d1afade5...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 149a0398b391cfc4eddb5e659f50b3c66f32ea65...\n",
            "Commit checked out successfully.\n",
            "Checking out commit 35b03788b0607c1f8d2b64e4fa9e1669b0907ea4...\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sphinx...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 752d3285d250bbaf673cff25e83f03f247502021...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit bd366ca2aeffa869b7dbc0b0aa01caea75e6dc31...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pytest...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit e6e300e729dd33956e5448d8be9a0b1540b4e53a...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pylint...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 3c5eca2ded3dd2b59ebaf23eb289453b5d2930f0...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 6df9398cce063874ae4d59db126d4adacb0fa8d3...Checking out commit 662cfb818e865f580e18b59efbb3540c34232beb...\n",
            "\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit bceadd2788dc2dad53eba0caae172bd8522fd483...\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/django...Cleaning untracked files in repository at /content/testbed/requests...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit fe693c492242ae532211e0c173324f09ca8cf227...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/requests...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit b330b918e979ea39a21d47b61172d112caf432c3...\n",
            "Checking out commit 0be38a0c37c59c4b66ce908731da15b401655113...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 66ba515e671638971bd11a34cff12c107a437e0b...\n",
            "Checking out commit 00ea883ef56fb5e092cbe4a6f7ff2e7470886ac4...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Commit checked out successfully.\n",
            "Checking out commit 479939f8c65c8c2908bbedc959549a257a7c0b0b...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit b4777fdcef467b7132c055f8ac2c9a5059e6a145...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit e7fd69d051eaa67cb17f172a39b57253e9cb831a...\n",
            "Checking out commit 58598660a3f6ab3d918781c4988c2e4b2bdd9297...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit f57fe3f4b3f2cab225749e1b3b38ae1bf80b62f0...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new indexCleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 65e86948b80262574058a94ccaae3a9b59c3faea...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sphinx...Cleaning untracked files in repository at /content/testbed/django...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c087d717f6ed183dd422359bf91210dc59689d63...\n",
            "Checking out commit 7f33c1e22dbc34a7afae7967783725b10f1f13b1...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit fb59d703e6863ed803c98177b59197b5513332e9...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sphinx...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 82ef497a8c88f0f6e50d84520e7276bfbf65025d...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/scikit-learn...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 3aefc834dce72e850bff48689bea3c7dff5f3fad...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/scikit-learn...\n",
            "Discarding changes in tracked files...\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit cd25abee0ad0ac95225d4a9be8948eff69f49690...\n",
            "Checking out commit 0456d3e42795481a186db05719300691fe2a1029...\n",
            "Checking out commit 58e78209c8577b9890e957b624466e5beed7eb08...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pylint...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 182cc539b8154c0710fcea7e522267e42eba8899...\n",
            "Checking out commit 755dbf39fcdc491fe9b588358303e259c7750be4...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/matplotlib...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7eafdd8af3c523c1c77b027d378fb337dd489f18...\n",
            "Creating new index\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pylint...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit e90702074e68e20dc8e5df5013ee3ecf22139c3e...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 879cc3da6249e920b8d54518a0ae06de835d7373...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/pylint...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit d597f252915ddcaaa15ccdfcb35670152cb83587...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/requests...\n",
            "Discarding changes in tracked files...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Checking out commit 110048f9837f8441ea536804115e80b69f400277...\n",
            "Creating new indexDiscarding changes in tracked files...\n",
            "\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 3546ac7ed78e1780c1a76929864bb33330055740...\n",
            "Checking out commit 7b9596b974fb0ad1868b10c8c2174e10b72be403...\n",
            "Commit checked out successfully.\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 03cadb912c78b769d6bf4a943a2a35fc1d952960...\n",
            "Commit checked out successfully.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 89d41cba392b759732ba9f1db4ff29ed47da6a56...\n",
            "Commit checked out successfully.\n",
            "Cleaning untracked files in repository at /content/testbed/django...Cleaning untracked files in repository at /content/testbed/astropy...\n",
            "\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit 7269fa3e33e8d02485a647da91a5a2a60a06af61...\n",
            "Checking out commit 2c01ebb4be5d53cbf6450f356c10e436025d6d07...\n",
            "Commit checked out successfully.\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'checkout', '2c01ebb4be5d53cbf6450f356c10e436025d6d07']' died with <Signals.SIGINT: 2>.\n",
            "Creating new index\n",
            "Cleaning untracked files in repository at /content/testbed/sympy...\n",
            "Cleaning untracked files in repository at /content/testbed/django...\n",
            "Discarding changes in tracked files...\n",
            "Discarding changes in tracked files...\n",
            "Checking out commit c807dfe7569692cad24f02a08477b70c1679a4dd...\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/sympy', 'checkout', 'c807dfe7569692cad24f02a08477b70c1679a4dd']' died with <Signals.SIGINT: 2>.\n",
            "An error occurred while running git command: Command '['git', '-C', '/content/testbed/django', 'reset', '--hard']' died with <Signals.SIGINT: 2>.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-17125c6c4a5f>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_to_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-17125c6c4a5f>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mretrieve_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mrows_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswe_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hcqFhH0Tw8sn",
        "outputId": "b1da77b5-e0a3-4cfc-cfa3-22075fa499b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n",
            "[-0.003275713650509715, -0.011690733022987843, 0.041559211909770966, -0.038148071616888046, 0.024183085188269615]\n"
          ]
        }
      ],
      "source": [
        "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "print(len(embeddings))\n",
        "print(embeddings[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38S5oaRSw8sn"
      },
      "source": [
        "## InstructorEmbedding\n",
        "\n",
        "Instructor Embeddings are a class of embeddings specifically trained to augment their embeddings according to an instruction. By default, queries are given `query_instruction=\"Represent the question for retrieving supporting documents: \"` and text is given `text_instruction=\"Represent the document for retrieval: \"`.\n",
        "\n",
        "They rely on the `Instructor` and `SentenceTransformers` (version 2.2.2) pip package, which you can install with `pip install InstructorEmbedding` and `pip install -U sentence-transformers==2.2.2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wwzKV98Yw8so",
        "outputId": "a8a35d76-5264-4218-a2c6-fb909e3c9f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-29cfa5294e9d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstructor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInstructorEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructorEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hkunlp/instructor-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_index/embeddings/instructor/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, query_instruction, text_instruction, embed_batch_size, cache_folder, device, callback_manager)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         )\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINSTRUCTOR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_sentence_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 modules = self._load_sbert_model(\n\u001b[0m\u001b[1;32m    198\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.instructor import InstructorEmbedding\n",
        "\n",
        "embed_model = InstructorEmbedding(model_name=\"hkunlp/instructor-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwR783JLw8so",
        "outputId": "6ac613fc-23ec-4f84-a2a8-ab71952f37d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "768\n",
            "[ 0.02155361 -0.06098218  0.01796207  0.05490903  0.01526906]\n"
          ]
        }
      ],
      "source": [
        "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "print(len(embeddings))\n",
        "print(embeddings[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVf6QJ5lw8so"
      },
      "source": [
        "## OptimumEmbedding\n",
        "\n",
        "Optimum in a HuggingFace library for exporting and running HuggingFace models in the ONNX format.\n",
        "\n",
        "You can install the dependencies with `pip install transformers optimum[exporters]`.\n",
        "\n",
        "First, we need to create the ONNX model. ONNX models provide improved inference speeds, and can be used across platforms (i.e. in TransformersJS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6uI_qZSw8so",
        "outputId": "d48c489e-52c5-460a-b275-b0441ce822b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/loganm/miniconda3/envs/llama-index/lib/python3.11/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "Framework not specified. Using pt to export to ONNX.\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.0.1+cu117\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "Saved optimum model to ./bge_onnx. Use it with `embed_model = OptimumEmbedding(folder_name='./bge_onnx')`.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
        "\n",
        "OptimumEmbedding.create_and_save_optimum_model(\n",
        "    \"BAAI/bge-small-en-v1.5\", \"./bge_onnx\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJSmvUOow8so"
      },
      "outputs": [],
      "source": [
        "embed_model = OptimumEmbedding(folder_name=\"./bge_onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRbdNr1pw8so",
        "outputId": "b8a32cd1-6e13-4d51-8a0c-36918876d9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "384\n",
            "[-0.10364960134029388, -0.20998482406139374, -0.01883639395236969, -0.5241696834564209, 0.0335749015212059]\n"
          ]
        }
      ],
      "source": [
        "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
        "print(len(embeddings))\n",
        "print(embeddings[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBA_xhZfw8so"
      },
      "source": [
        "## Benchmarking\n",
        "\n",
        "Let's try comparing using a classic large document -- the IPCC climate report, chapter 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZJ4RPGw8sp",
        "outputId": "02766485-43e0-4ea5-904b-c3b91849cf0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 20.7M  100 20.7M    0     0  16.5M      0  0:00:01  0:00:01 --:--:-- 16.5M\n"
          ]
        }
      ],
      "source": [
        "!curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "434uPetLw8sp"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import Settings\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"IPCC_AR6_WGII_Chapter03.pdf\"]\n",
        ").load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UCCpNbw8sp"
      },
      "source": [
        "### Base HuggingFace Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B6l9hj0w8sp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# needed to synthesize responses later\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW290ymbw8sp"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# loads BAAI/bge-small-en-v1.5\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "test_emeds = embed_model.get_text_embedding(\"Hello World!\")\n",
        "\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FrC24f9w8sq",
        "outputId": "8c2cc598-5fa3-43dc-dae1-5c8644006e1b",
        "colab": {
          "referenced_widgets": [
            "3bfb6c2115c447e5af19bb18b5a07ebe",
            "55c188c3d18049df933cd87bd5a49ed1"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bfb6c2115c447e5af19bb18b5a07ebe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing documents into nodes:   0%|          | 0/172 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c188c3d18049df933cd87bd5a49ed1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/428 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1min 27s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -r 1 -n 1\n",
        "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKiFj5ivw8sq"
      },
      "source": [
        "### Optimum Embeddings\n",
        "\n",
        "We can use the onnx embeddings we created earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA6j0OFJw8sq"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding\n",
        "\n",
        "embed_model = OptimumEmbedding(folder_name=\"./bge_onnx\")\n",
        "test_emeds = embed_model.get_text_embedding(\"Hello World!\")\n",
        "\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEIg1TmGw8sq",
        "outputId": "69ef4e3e-2690-4904-e2d0-518f3c876360",
        "colab": {
          "referenced_widgets": [
            "cf49fd773c6f486f9fee323db590bcd5",
            "7f1f3f8a5d3140bd9982a158a6ef9b9f"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf49fd773c6f486f9fee323db590bcd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Parsing documents into nodes:   0%|          | 0/172 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f1f3f8a5d3140bd9982a158a6ef9b9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating embeddings:   0%|          | 0/428 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1min 9s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -r 1 -n 1\n",
        "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama-index",
      "language": "python",
      "name": "llama-index"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}